{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T04:32:56.489133Z",
     "start_time": "2018-01-21T04:32:55.890714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "import scipy.io as sio\n",
    "plt.rcParams['figure.figsize'] = 8,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_and_Y_train = np.load('./q2-logistic-train.npy')\n",
    "X_train = X_and_Y_train[:, :2]    # Shape: (70,2)\n",
    "########### YOUR CODE HERE ###########\n",
    "#         Append bias term 1        #\n",
    "########### YOUR CODE HERE ##########\n",
    "Y_train = X_and_Y_train[:, 2]    # Shape: (70,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_and_Y_test = np.load('./q2-logistic-test.npy')\n",
    "X_test = X_and_Y_test[:, :2]   # Shape: (70,2)\n",
    "########### YOUR CODE HERE ###########\n",
    "#         Append bias term 1        #\n",
    "########### YOUR CODE HERE ##########\n",
    "Y_test = X_and_Y_test[:, 2]    # Shape: (70,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X_train[Y_train==0, 1], X_train[Y_train==0, 2], marker='x', color='b', alpha=0.7, s=10, label='class 0')\n",
    "plt.scatter(X_train[Y_train==1, 1], X_train[Y_train==1, 2], marker='o', color='r', alpha=0.7, s=10, label='class 1')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "plt.title('Training data')\n",
    "plt.show()\n",
    "#fig.savefig('scatter_1.png', format='png', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-21T05:02:10.129529Z",
     "start_time": "2018-01-21T05:02:10.123934Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient of loss function L(theta)\n",
    "def L_prime_theta(X, Y, theta):\n",
    "    ########### YOUR CODE HERE ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_theta(X, Y, theta):\n",
    "    ########### YOUR CODE HERE ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_iter = 10000\n",
    "theta = np.zeros((X_train.shape[1], 1))\n",
    "# We will keep track of training loss over iterations\n",
    "iterations = [0]\n",
    "L_theta_list = [L_theta(X_train, Y_train, theta)]\n",
    "for i in range(n_iter):\n",
    "    gradient = L_prime_theta(X_train, Y_train, theta)\n",
    "    theta_new = theta - learning_rate * gradient\n",
    "    iterations.append(i+1)\n",
    "    L_theta_list.append(L_theta(X_train, Y_train, theta_new))\n",
    "\n",
    "    if np.linalg.norm(theta_new - theta, ord = 1) < 0.001:\n",
    "        print(\"gradient descent has converged after \" + str(i) + \" iterations\")\n",
    "        break\n",
    "    theta = theta_new\n",
    "    \n",
    "print (\"theta vector: \\n\" + str(theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Training curve')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('L(theta)')\n",
    "plt.semilogy(iterations, np.array(L_theta_list).reshape(-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sigmoid(np.dot(X_train, theta)) >= 0.5\n",
    "testing_accuracy = np.sum(prediction == Y_train.reshape(-1, 1))*1.0/X_train.shape[0]\n",
    "print(prediction.shape, Y_test.shape)\n",
    "print (\"training accuracy: \" + str(testing_accuracy))\n",
    "\n",
    "x = np.arange(np.min(X_train[:,1])-1,np.max(X_train[:,1])+1,1.0)\n",
    "y = (-theta[0][0]-theta[1][0]*x)/theta[2][0]\n",
    "plt.scatter(X_train[Y_train==0, 1], X_train[Y_train==0, 2], marker='x', color='b', alpha=0.7, s=10, label='class 0')\n",
    "plt.scatter(X_train[Y_train==1, 1], X_train[Y_train==1, 2], marker='o', color='r', alpha=0.7, s=10, label='class 1')\n",
    "\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.plot(x,y, 'dodgerblue', label='decision boundary')\n",
    "plt.title('Training data and decision boundary')\n",
    "\n",
    "plt.legend(loc='upper right', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sigmoid(np.dot(X_test, theta)) >= 0.5\n",
    "testing_accuracy = np.sum(prediction == Y_test.reshape(-1, 1))*1.0/X_test.shape[0]\n",
    "print (\"testing accuracy: \" + str(testing_accuracy))\n",
    "\n",
    "x = np.arange(np.min(X_train[:,1])-1,np.max(X_train[:,1])+1,1.0)\n",
    "y = (-theta[0][0]-theta[1][0]*x)/theta[2][0]\n",
    "plt.scatter(X_test[Y_test==0, 1], X_test[Y_test==0, 2], marker='x', color='b', alpha=0.7, s=10, label='class 0')\n",
    "plt.scatter(X_test[Y_test==1, 1], X_test[Y_test==1, 2], marker='o', color='r', alpha=0.7, s=10, label='class 1')\n",
    "\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.plot(x,y, 'dodgerblue', label='decision boundary')\n",
    "plt.title('Testing data and decision boundary')\n",
    "\n",
    "plt.legend(loc='upper right', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
